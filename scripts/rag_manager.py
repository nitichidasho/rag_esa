#!/usr/bin/env python3
"""
ç ”ç©¶å®¤RAGã‚·ã‚¹ãƒ†ãƒ  çµ±åˆç®¡ç†ã‚³ãƒãƒ³ãƒ‰
"""

import sys
import argparse
from pathlib import Path
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ sys.path ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.config.settings import settings


def setup_argument_parser():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è¨­å®š"""
    parser = argparse.ArgumentParser(
        description="ç ”ç©¶å®¤RAGã‚·ã‚¹ãƒ†ãƒ  çµ±åˆç®¡ç†ã‚³ãƒãƒ³ãƒ‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python rag_manager.py export           # esa.io ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
  python rag_manager.py vectorize        # è¨˜äº‹ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
  python rag_manager.py vectorize --enhanced  # å¼·åŒ–ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆé«˜ç²¾åº¦ï¼‰
  python rag_manager.py vectorize --force --enhanced  # å…¨è¨˜äº‹ã‚’å¼·åŒ–å†ãƒ™ã‚¯ãƒˆãƒ«åŒ–
  python rag_manager.py vectorize --model intfloat/multilingual-e5-base  # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
  python rag_manager.py check           # ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèª
  python rag_manager.py check --detailed --verify-vectors  # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª
  python rag_manager.py search "æ¤œç´¢èª"  # è¨˜äº‹ã‚’æ¤œç´¢
  python rag_manager.py search "ç­‹é›»" --find-article 818  # ç‰¹å®šè¨˜äº‹ã®æ¤œç´¢å¯¾è±¡ç¢ºèª
  python rag_manager.py search "Ubuntu ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«" --hybrid  # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
  python rag_manager.py search "ROS ã‚¨ãƒ©ãƒ¼" --hybrid --explain  # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆè©³ç´°è¡¨ç¤ºï¼‰
  python rag_manager.py search "æ©Ÿæ¢°å­¦ç¿’" --hybrid --sparse-weight 0.8 --dense-weight 0.2  # é‡ã¿èª¿æ•´
  python rag_manager.py serve           # Webã‚¢ãƒ—ãƒªã‚’èµ·å‹•
  python rag_manager.py full            # å…¨ä½“å‡¦ç†ï¼ˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ+ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
  python rag_manager.py full --enhanced # å…¨ä½“å‡¦ç†ï¼ˆå¼·åŒ–ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
  python rag_manager.py full --skip-export --enhanced --force  # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®ã¿å¼·åŒ–ãƒ¢ãƒ¼ãƒ‰
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰')
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚³ãƒãƒ³ãƒ‰
    export_parser = subparsers.add_parser('export', help='esa.io ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ')
    export_parser.add_argument('--members-only', action='store_true', help='ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã®ã¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ')
    export_parser.add_argument('--articles-only', action='store_true', help='è¨˜äº‹æƒ…å ±ã®ã¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ')
    
    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚³ãƒãƒ³ãƒ‰
    vectorize_parser = subparsers.add_parser('vectorize', help='è¨˜äº‹ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–')
    vectorize_parser.add_argument('--force', action='store_true', help='æ—¢å­˜ãƒ™ã‚¯ãƒˆãƒ«ã‚‚å†ç”Ÿæˆ')
    vectorize_parser.add_argument('--enhanced', action='store_true', help='å¼·åŒ–ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ»é«˜ç²¾åº¦ï¼‰')
    vectorize_parser.add_argument('--model', type=str, help='ä½¿ç”¨ã™ã‚‹embeddingãƒ¢ãƒ‡ãƒ«å')
    
    # ãƒ‡ãƒ¼ã‚¿ç¢ºèªã‚³ãƒãƒ³ãƒ‰
    check_parser = subparsers.add_parser('check', help='ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèª')
    check_parser.add_argument('--detailed', action='store_true', help='è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º')
    check_parser.add_argument('--verify-vectors', action='store_true', help='ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ç¢ºèª')
    
    # æ¤œç´¢ã‚³ãƒãƒ³ãƒ‰
    search_parser = subparsers.add_parser('search', help='è¨˜äº‹ã‚’æ¤œç´¢')
    search_parser.add_argument('query', help='æ¤œç´¢ã‚¯ã‚¨ãƒª')
    search_parser.add_argument('--limit', type=int, default=5, help='è¡¨ç¤ºä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰')
    search_parser.add_argument('--find-article', type=int, help='ç‰¹å®šã®è¨˜äº‹ç•ªå·ã‚’æ¤œç´¢å¯¾è±¡ã«å«ã‚ã¦ç¢ºèª')
    search_parser.add_argument('--hybrid', action='store_true', help='ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’ä½¿ç”¨ï¼ˆBM25 + ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰')
    search_parser.add_argument('--sparse-weight', type=float, default=0.7, help='ã‚¹ãƒ‘ãƒ¼ã‚¹æ¤œç´¢ï¼ˆBM25ï¼‰ã®é‡ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.7ï¼‰')
    search_parser.add_argument('--dense-weight', type=float, default=0.3, help='å¯†ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®é‡ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.3ï¼‰')
    search_parser.add_argument('--explain', action='store_true', help='æ¤œç´¢çµæœã®è©³ç´°ã‚¹ã‚³ã‚¢æƒ…å ±ã‚’è¡¨ç¤º')
    
    # Webã‚¢ãƒ—ãƒªèµ·å‹•ã‚³ãƒãƒ³ãƒ‰
    serve_parser = subparsers.add_parser('serve', help='Webã‚¢ãƒ—ãƒªã‚’èµ·å‹•')
    serve_parser.add_argument('--port', type=int, default=8000, help='ãƒãƒ¼ãƒˆç•ªå·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8000ï¼‰')
    serve_parser.add_argument('--frontend', action='store_true', help='ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚‚èµ·å‹•')
    
    # å…¨ä½“å‡¦ç†ã‚³ãƒãƒ³ãƒ‰
    full_parser = subparsers.add_parser('full', help='å…¨ä½“å‡¦ç†ï¼ˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ+ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰')
    full_parser.add_argument('--skip-export', action='store_true', help='ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—')
    full_parser.add_argument('--enhanced', action='store_true', help='å¼·åŒ–ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ»é«˜ç²¾åº¦ï¼‰')
    full_parser.add_argument('--force', action='store_true', help='æ—¢å­˜ãƒ™ã‚¯ãƒˆãƒ«ã‚‚å†ç”Ÿæˆ')
    full_parser.add_argument('--model', type=str, help='ä½¿ç”¨ã™ã‚‹embeddingãƒ¢ãƒ‡ãƒ«å')
    
    return parser


def export_data(args):
    """ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå‡¦ç†"""
    print("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå‡¦ç†ã‚’é–‹å§‹...")
    
    # export_esa_data.pyã®æ©Ÿèƒ½ã‚’ç›´æ¥å®Ÿè¡Œ
    try:
        import sys
        from pathlib import Path
        from datetime import datetime
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ sys.path ã«è¿½åŠ 
        project_root = Path(__file__).parent.parent
        sys.path.insert(0, str(project_root))
        
        from src.services.esa_api_service import EsaAPIClient
        from src.database.repositories.article_repository import ArticleRepository
        from src.database.repositories.member_repository import MemberRepository
        from src.services.search_service import SearchService
        from src.services.embedding_service import EmbeddingService
        from src.database.connection import SessionLocal
        
        # ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        print("ğŸ”§ ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–ä¸­...")
        
        # åŸ‹ã‚è¾¼ã¿ã‚µãƒ¼ãƒ“ã‚¹ã¨SearchServiceã‚’å…ˆã«åˆæœŸåŒ–
        embedding_service = EmbeddingService()
        search_service = SearchService()
        print("âœ… ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å®Œäº†")
        
        api_client = EsaAPIClient()
        db_session = SessionLocal()
        
        try:
            article_repo = ArticleRepository(db=db_session)
            member_repo = MemberRepository(db=db_session)
            
            # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³å¼•æ•°ãƒã‚§ãƒƒã‚¯ï¼‰
            if not getattr(args, 'articles_only', False):
                from scripts.export_esa_data import export_members
                member_count = export_members(api_client, member_repo)
            else:
                member_count = 0
                print("â­ï¸ ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
            
            # è¨˜äº‹æƒ…å ±ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³å¼•æ•°ãƒã‚§ãƒƒã‚¯ï¼‰
            if not getattr(args, 'members_only', False):
                from scripts.export_esa_data import export_articles
                article_count = export_articles(api_client, article_repo)
            else:
                article_count = 0
                print("â­ï¸ è¨˜äº‹æƒ…å ±ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
            
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ")
            if member_count > 0:
                print(f"   ãƒ¡ãƒ³ãƒãƒ¼: {member_count}äºº")
            if article_count > 0:
                print(f"   è¨˜äº‹: {article_count}ä»¶")
            
        finally:
            db_session.close()
            
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(f"   è©³ç´°: {traceback.format_exc()}")
        sys.exit(1)


def vectorize_articles(args):
    """è¨˜äº‹ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    enhanced_mode = getattr(args, 'enhanced', False)
    custom_model = getattr(args, 'model', None)
    
    if enhanced_mode:
        print("ğŸ”„ å¼·åŒ–ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ã‚’é–‹å§‹...")
        print("   âœ¨ ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã«ã‚ˆã‚‹é«˜ç²¾åº¦å‡¦ç†")
        print("   âœ¨ æƒ…å ±æå¤±ã‚’æœ€å°åŒ–")
    else:
        print("ğŸ”„ è¨˜äº‹ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†ã‚’é–‹å§‹...")
    
    if custom_model:
        print(f"   ğŸ¯ ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«: {custom_model}")
    
    try:
        import sys
        from pathlib import Path
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ sys.path ã«è¿½åŠ 
        project_root = Path(__file__).parent.parent
        sys.path.insert(0, str(project_root))
        
        from src.database.repositories.article_repository import ArticleRepository
        from src.services.search_service import SearchService
        from src.services.embedding_service import EmbeddingService
        from src.database.connection import SessionLocal
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
        db_session = SessionLocal()
        
        try:
            article_repo = ArticleRepository(db=db_session)
            
            # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«æŒ‡å®šã®å ´åˆã¯ä¸€æ™‚çš„ã«è¨­å®šå¤‰æ›´
            if custom_model:
                from src.config.settings import settings
                original_model = settings.hf_model_name
                settings.hf_model_name = custom_model
                print(f"   ğŸ“ ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ™‚å¤‰æ›´: {original_model} â†’ {custom_model}")
            
            # åŸ‹ã‚è¾¼ã¿ã‚µãƒ¼ãƒ“ã‚¹ã¨SearchServiceã‚’åˆæœŸåŒ–
            embedding_service = EmbeddingService()
            search_service = SearchService()
            
            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Ÿè¡Œ
            force_regenerate = getattr(args, 'force', False)
            
            from scripts.export_esa_data import generate_embeddings_enhanced
            vector_count = generate_embeddings_enhanced(
                article_repo, 
                search_service, 
                skip_existing=not force_regenerate,
                use_enhanced_mode=enhanced_mode
            )
            
            # ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’å…ƒã«æˆ»ã™
            if custom_model:
                settings.hf_model_name = original_model
                print(f"   ğŸ“ ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’å¾©å…ƒ: {custom_model} â†’ {original_model}")
            
            print(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
            print(f"   ãƒ™ã‚¯ãƒˆãƒ«åŒ–è¨˜äº‹æ•°: {vector_count}ä»¶")
            if enhanced_mode:
                print(f"   ğŸ¯ å¼·åŒ–ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã‚‹é«˜ç²¾åº¦å‡¦ç†å®Œäº†")
            
        finally:
            db_session.close()
            
    except Exception as e:
        print(f"âŒ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(f"   è©³ç´°: {traceback.format_exc()}")
        sys.exit(1)


def check_data(args):
    """ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ç¢ºèª"""
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ã‚’ç¢ºèªä¸­...")
    
    try:
        import sys
        from pathlib import Path
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ sys.path ã«è¿½åŠ 
        project_root = Path(__file__).parent.parent
        sys.path.insert(0, str(project_root))
        
        from src.database.repositories.article_repository import ArticleRepository
        from src.database.repositories.member_repository import MemberRepository
        from src.database.connection import SessionLocal
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
        db_session = SessionLocal()
        
        try:
            article_repo = ArticleRepository(db=db_session)
            member_repo = MemberRepository(db=db_session)
            
            # ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ç¢ºèª
            articles = article_repo.get_all(limit=None)
            members = member_repo.get_all()
            
            vectorized_articles = [a for a in articles if a.embedding is not None]
            unvectorized_articles = [a for a in articles if a.embedding is None]
            
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿çŠ¶æ³:")
            print(f"   ãƒ¡ãƒ³ãƒãƒ¼æ•°: {len(members)}äºº")
            print(f"   ç·è¨˜äº‹æ•°: {len(articles)}ä»¶")
            print(f"   ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¸ˆã¿: {len(vectorized_articles)}ä»¶")
            print(f"   æœªãƒ™ã‚¯ãƒˆãƒ«åŒ–: {len(unvectorized_articles)}ä»¶")
            
            if len(articles) > 0:
                vectorization_rate = len(vectorized_articles) / len(articles) * 100
                print(f"   ãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‡: {vectorization_rate:.1f}%")
            
            # è©³ç´°æƒ…å ±ã®è¡¨ç¤º
            detailed = getattr(args, 'detailed', False)
            if detailed:
                print(f"\nğŸ“‹ è©³ç´°æƒ…å ±:")
                
                # æœ€æ–°è¨˜äº‹ã®ç¢ºèª
                if articles:
                    recent_articles = sorted(articles, key=lambda x: x.updated_at or x.created_at, reverse=True)[:5]
                    print(f"\næœ€æ–°è¨˜äº‹ï¼ˆä¸Šä½5ä»¶ï¼‰:")
                    for i, article in enumerate(recent_articles, 1):
                        print(f"  {i}. è¨˜äº‹{article.number}: {article.name}")
                        print(f"     æ›´æ–°æ—¥: {article.updated_at}")
                        print(f"     ã‚«ãƒ†ã‚´ãƒª: {article.category}")
                        print(f"     ãƒ™ã‚¯ãƒˆãƒ«åŒ–: {'âœ…' if article.embedding else 'âŒ'}")
                        print(f"     ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(article.processed_text or article.body_md or '') if article.processed_text or article.body_md else 0}æ–‡å­—")
                        print()
                
                # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
                categories = {}
                for article in articles:
                    cat = article.category or "æœªåˆ†é¡"
                    categories[cat] = categories.get(cat, 0) + 1
                
                print(f"ğŸ“‚ ã‚«ãƒ†ã‚´ãƒªåˆ¥è¨˜äº‹æ•°:")
                for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:10]:
                    print(f"   {cat}: {count}ä»¶")
                
                # ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç¢ºèª
                try:
                    from src.services.search_service import SearchService
                    search_service = SearchService()
                    
                    # ChromaDBã‹ã‚‰ç›´æ¥ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
                    collection = search_service.collection
                    chroma_count = collection.count()
                    print(f"\nğŸ” ChromaDBã®çŠ¶æ³:")
                    print(f"   ãƒ™ã‚¯ãƒˆãƒ«DBå†…è¨˜äº‹æ•°: {chroma_count}ä»¶")
                    
                    if chroma_count != len(vectorized_articles):
                        print(f"   âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ™ã‚¯ãƒˆãƒ«DBã®ä»¶æ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“")
                        print(f"   ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {len(vectorized_articles)}ä»¶")
                        print(f"   ãƒ™ã‚¯ãƒˆãƒ«DB: {chroma_count}ä»¶")
                    
                    # ãƒ™ã‚¯ãƒˆãƒ«æ•´åˆæ€§ç¢ºèª
                    verify_vectors = getattr(args, 'verify_vectors', False)
                    if verify_vectors:
                        print(f"\nğŸ” ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª:")
                        
                        # ã‚µãƒ³ãƒ—ãƒ«è¨˜äº‹ã§ç¢ºèª
                        sample_articles = vectorized_articles[:5]  # æœ€åˆã®5ä»¶ã‚’ã‚µãƒ³ãƒ—ãƒ«
                        for article in sample_articles:
                            try:
                                # SQLiteã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«å–å¾—
                                sqlite_embedding = article.embedding
                                
                                # ChromaDBã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«å–å¾—
                                chroma_result = collection.get(
                                    ids=[str(article.number)],
                                    include=["embeddings"]
                                )
                                
                                if chroma_result["embeddings"]:
                                    chroma_embedding = chroma_result["embeddings"][0]
                                    
                                    # ãƒ™ã‚¯ãƒˆãƒ«ã‚µã‚¤ã‚ºç¢ºèª
                                    sqlite_size = len(sqlite_embedding) if sqlite_embedding else 0
                                    chroma_size = len(chroma_embedding) if chroma_embedding else 0
                                    
                                    if sqlite_size == chroma_size and sqlite_size > 0:
                                        # æœ€åˆã®3è¦ç´ ã‚’æ¯”è¼ƒï¼ˆå®Œå…¨ä¸€è‡´ã¯è¨ˆç®—èª¤å·®ã‚‚ã‚ã‚‹ã®ã§è¿‘ä¼¼æ¯”è¼ƒï¼‰
                                        import numpy as np
                                        sqlite_vec = np.array(sqlite_embedding[:3])
                                        chroma_vec = np.array(chroma_embedding[:3])
                                        similarity = np.dot(sqlite_vec, chroma_vec)
                                        
                                        if similarity > 0.99:  # éå¸¸ã«é«˜ã„é¡ä¼¼åº¦
                                            status = "âœ…"
                                        else:
                                            status = "âš ï¸"
                                        
                                        print(f"   è¨˜äº‹{article.number}: {status} SQLite({sqlite_size}) â†” Chroma({chroma_size}) é¡ä¼¼åº¦:{similarity:.4f}")
                                    else:
                                        print(f"   è¨˜äº‹{article.number}: âŒ ã‚µã‚¤ã‚ºä¸ä¸€è‡´ SQLite({sqlite_size}) â†” Chroma({chroma_size})")
                                else:
                                    print(f"   è¨˜äº‹{article.number}: âŒ ChromaDBã«ãƒ™ã‚¯ãƒˆãƒ«ãªã—")
                                    
                            except Exception as verify_error:
                                print(f"   è¨˜äº‹{article.number}: âŒ ç¢ºèªã‚¨ãƒ©ãƒ¼: {verify_error}")
                        
                        print(f"\nğŸ“Š ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª¬æ˜:")
                        print(f"   SQLite: JSONãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ã—ã¦è¨˜äº‹ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜")
                        print(f"   ChromaDB: å°‚ç”¨ãƒ™ã‚¯ãƒˆãƒ«DBã§é«˜é€Ÿæ¤œç´¢ã«æœ€é©åŒ–")
                        print(f"   ãƒ‡ãƒ¼ã‚¿åŒæœŸ: ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ™‚ã«ä¸¡æ–¹ã«åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜")
                    
                except Exception as search_error:
                    print(f"   âŒ ãƒ™ã‚¯ãƒˆãƒ«DBç¢ºèªã‚¨ãƒ©ãƒ¼: {search_error}")
            
        finally:
            db_session.close()
            
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(f"   è©³ç´°: {traceback.format_exc()}")
        sys.exit(1)


def search_articles(args):
    """è¨˜äº‹æ¤œç´¢ï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢å¯¾å¿œç‰ˆï¼‰"""
    search_type = "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰" if args.hybrid else "ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯"
    print(f"ğŸ” '{args.query}' ã§è¨˜äº‹ã‚’{search_type}æ¤œç´¢ä¸­...")
    
    if args.hybrid:
        print(f"   âš–ï¸  ã‚¹ãƒ‘ãƒ¼ã‚¹é‡ã¿: {args.sparse_weight:.1f}, å¯†ãƒ™ã‚¯ãƒˆãƒ«é‡ã¿: {args.dense_weight:.1f}")
    
    # ç‰¹å®šè¨˜äº‹ç¢ºèªã‚ªãƒ—ã‚·ãƒ§ãƒ³
    find_article_num = getattr(args, 'find_article', None)
    if find_article_num:
        print(f"   ğŸ¯ è¨˜äº‹{find_article_num}ã®æ¤œç´¢å¯¾è±¡ç¢ºèªã‚‚å®Ÿè¡Œ")
    
    try:
        if args.hybrid:
            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’ä½¿ç”¨
            from src.services.hybrid_search_service import HybridSearchService
            search_service = HybridSearchService()
        else:
            # å¾“æ¥ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚’ä½¿ç”¨
            from src.services.search_service import SearchService
            search_service = SearchService()
        
        from src.database.repositories.article_repository import ArticleRepository
        from src.database.connection import SessionLocal
        
        # ç‰¹å®šè¨˜äº‹ã®ç¢ºèª
        if find_article_num:
            print(f"\nğŸ” è¨˜äº‹{find_article_num}ã®ç¢ºèª:")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—
            db_session = SessionLocal()
            try:
                article_repo = ArticleRepository(db=db_session)
                target_article = article_repo.get_by_number(find_article_num)
                
                if target_article:
                    print(f"   âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã«å­˜åœ¨:")
                    print(f"      ã‚¿ã‚¤ãƒˆãƒ«: {target_article.name}")
                    print(f"      ã‚«ãƒ†ã‚´ãƒª: {target_article.category}")
                    print(f"      ãƒ™ã‚¯ãƒˆãƒ«åŒ–: {'âœ…' if target_article.embedding else 'âŒ'}")
                    print(f"      ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(target_article.processed_text or '') if target_article.processed_text else 0}æ–‡å­—")
                    
                    # ChromaDBã§ã®ç¢ºèª
                    try:
                        if args.hybrid:
                            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ã®å ´åˆ
                            collection = search_service.search_service.collection
                        else:
                            collection = search_service.collection
                            
                        chroma_result = collection.get(
                            ids=[str(find_article_num)],
                            include=["metadatas", "documents"]
                        )
                        
                        if chroma_result["ids"]:
                            print(f"   âœ… ChromaDBå†…ã«å­˜åœ¨")
                            chroma_title = chroma_result["metadatas"][0].get("name", "")
                            print(f"      ChromaDBã‚¿ã‚¤ãƒˆãƒ«: {chroma_title}")
                        else:
                            print(f"   âŒ ChromaDBå†…ã«å­˜åœ¨ã—ã¾ã›ã‚“")
                            
                    except Exception as chroma_error:
                        print(f"   âŒ ChromaDBç¢ºèªã‚¨ãƒ©ãƒ¼: {chroma_error}")
                        
                else:
                    print(f"   âŒ è¨˜äº‹{find_article_num}ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã«å­˜åœ¨ã—ã¾ã›ã‚“")
                    
            finally:
                db_session.close()
            
            print()
        
        # æ¤œç´¢å®Ÿè¡Œ
        if args.hybrid:
            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
            import asyncio
            results = asyncio.run(search_service.hybrid_search(
                query=args.query,
                limit=args.limit,
                sparse_weight=args.sparse_weight,
                dense_weight=args.dense_weight
            ))
            
            # è©³ç´°èª¬æ˜ãŒè¦æ±‚ã•ã‚ŒãŸå ´åˆ
            if args.explain and results:
                print(f"\nğŸ“Š æ¤œç´¢è©³ç´°æƒ…å ±:")
                explain_results = search_service.explain_search(
                    query=args.query,
                    limit=3  # ä¸Šä½3ä»¶ã®ã¿èª¬æ˜
                )
                
                # èª¬æ˜çµæœã‚’æ•´å½¢ã—ã¦è¡¨ç¤º
                print(f"ã‚¯ã‚¨ãƒªå‡¦ç†:")
                print(f"  å…ƒã‚¯ã‚¨ãƒª: {explain_results['original_query']}")
                print(f"  æ­£è¦åŒ–: {explain_results['query_processing']['normalized']}")
                print(f"  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {explain_results['query_processing']['keywords']}")
                print(f"  æ¨å¥¨ã‚¯ã‚¨ãƒª: {explain_results['query_processing']['recommended']}")
                print(f"æ¤œç´¢é‡ã¿:")
                print(f"  ã‚¹ãƒ‘ãƒ¼ã‚¹: {explain_results['search_weights']['sparse_weight']}")
                print(f"  å¯†ãƒ™ã‚¯ãƒˆãƒ«: {explain_results['search_weights']['dense_weight']}")
                print(f"çµæœè©³ç´°:")
                for i, result_detail in enumerate(explain_results['results'][:3], 1):
                    print(f"  {i}. {result_detail['title']}")
                    print(f"     æœ€çµ‚ã‚¹ã‚³ã‚¢: {result_detail['hybrid_score']:.3f}")
                    print(f"     ã‚¹ãƒ‘ãƒ¼ã‚¹: {result_detail['sparse_score']:.3f}")
                    print(f"     å¯†ãƒ™ã‚¯ãƒˆãƒ«: {result_detail['dense_score']:.3f}")
                    print(f"     æ¤œç´¢ã‚¿ã‚¤ãƒ—: {result_detail['search_type']}")
                
                # çµæœåˆ†å¸ƒã‚‚è¡¨ç¤º
                distribution = explain_results['result_distribution']
                print(f"æ¤œç´¢ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ:")
                print(f"  ã‚¹ãƒ‘ãƒ¼ã‚¹å°‚ç”¨: {distribution['sparse_only']}ä»¶")
                print(f"  å¯†ãƒ™ã‚¯ãƒˆãƒ«å°‚ç”¨: {distribution['dense_only']}ä»¶")  
                print(f"  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰: {distribution['hybrid']}ä»¶")
                print()
        else:
            # å¾“æ¥ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
            results = search_service.semantic_search(args.query, limit=args.limit)
        
        if results:
            print(f"âœ… {len(results)}ä»¶ã®æ¤œç´¢çµæœ:")
            for i, result in enumerate(results, 1):
                if args.hybrid:
                    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢çµæœã®è¡¨ç¤º
                    print(f"\n{i}. è¨˜äº‹{result.article_id}: {result.title}")
                    print(f"   ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¹ã‚³ã‚¢: {result.hybrid_score:.4f}")
                    print(f"   ã‚¹ãƒ‘ãƒ¼ã‚¹BM25: {result.sparse_score:.4f}")
                    print(f"   å¯†ãƒ™ã‚¯ãƒˆãƒ«: {result.dense_score:.4f}")
                    print(f"   æ¤œç´¢ã‚¿ã‚¤ãƒ—: {result.search_type}")
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã®ä¸€éƒ¨è¡¨ç¤º
                    if result.content:
                        content_preview = result.content[:150] + "..." if len(result.content) > 150 else result.content
                        print(f"   å†…å®¹: {content_preview}")
                        print(f"   ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(result.content)}æ–‡å­—")
                    
                    # ç‰¹å®šè¨˜äº‹ãŒãƒ’ãƒƒãƒˆã—ãŸã‹ãƒã‚§ãƒƒã‚¯
                    if find_article_num and result.article_id == find_article_num:
                        print(f"   ğŸ¯ æ¢ã—ã¦ã„ãŸè¨˜äº‹{find_article_num}ãŒæ¤œç´¢çµæœã«å«ã¾ã‚Œã¾ã—ãŸï¼")
                else:
                    # å¾“æ¥ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢çµæœã®è¡¨ç¤º
                    print(f"\n{i}. è¨˜äº‹{result.article.number}: {result.article.name}")
                    print(f"   ã‚¹ã‚³ã‚¢: {result.score:.4f}")
                    print(f"   ã‚«ãƒ†ã‚´ãƒª: {result.article.category or 'æœªåˆ†é¡'}")
                    print(f"   æ›´æ–°æ—¥: {result.article.updated_at}")
                    print(f"   URL: {result.article.url}")
                    if result.matched_text:
                        print(f"   ãƒãƒƒãƒ: {result.matched_text[:150]}...")
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã®ç¢ºèª
                    content_length = len(result.article.processed_text or result.article.body_md or '')
                    print(f"   ãƒ†ã‚­ã‚¹ãƒˆé•·: {content_length}æ–‡å­—")
                    
                    # ç‰¹å®šè¨˜äº‹ãŒãƒ’ãƒƒãƒˆã—ãŸã‹ãƒã‚§ãƒƒã‚¯
                    if find_article_num and result.article.number == find_article_num:
                        print(f"   ğŸ¯ æ¢ã—ã¦ã„ãŸè¨˜äº‹{find_article_num}ãŒæ¤œç´¢çµæœã«å«ã¾ã‚Œã¾ã—ãŸï¼")
        else:
            print("âŒ æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
            print("\nğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
            try:
                if args.hybrid:
                    collection = search_service.search_service.collection
                else:
                    collection = search_service.collection
                    
                total_count = collection.count()
                print(f"   ãƒ™ã‚¯ãƒˆãƒ«DBå†…è¨˜äº‹æ•°: {total_count}ä»¶")
                
                if total_count == 0:
                    print("   âš ï¸ ãƒ™ã‚¯ãƒˆãƒ«DBãŒç©ºã§ã™ã€‚ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                else:
                    # ã‚µãƒ³ãƒ—ãƒ«æ¤œç´¢ã§å‹•ä½œç¢ºèª
                    if args.hybrid:
                        import asyncio
                        sample_results = asyncio.run(search_service.hybrid_search("ç ”ç©¶", limit=3))
                    else:
                        sample_results = search_service.semantic_search("ç ”ç©¶", limit=3)
                    print(f"   ã‚µãƒ³ãƒ—ãƒ«æ¤œç´¢('ç ”ç©¶'): {len(sample_results)}ä»¶")
                    
            except Exception as debug_error:
                print(f"   âŒ ãƒ‡ãƒãƒƒã‚°æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {debug_error}")
            
    except Exception as e:
        print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        print(f"   è©³ç´°: {traceback.format_exc()}")
        sys.exit(1)


def serve_app(args):
    """Webã‚¢ãƒ—ãƒªèµ·å‹•"""
    print(f"ğŸš€ Webã‚¢ãƒ—ãƒªã‚’ãƒãƒ¼ãƒˆ{args.port}ã§èµ·å‹•ä¸­...")
    
    try:
        import subprocess
        import os
        
        # APIã‚µãƒ¼ãƒãƒ¼èµ·å‹•
        api_cmd = [
            sys.executable, "-m", "uvicorn",
            "src.api.main:app",
            "--host", "0.0.0.0",
            "--port", str(args.port),
            "--reload"
        ]
        
        print(f"ğŸ“¡ APIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•: http://localhost:{args.port}")
        
        if args.frontend:
            # ç’°å¢ƒå¤‰æ•°ã§APIãƒãƒ¼ãƒˆã‚’ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã«ä¼é”
            frontend_env = os.environ.copy()
            frontend_env["API_PORT"] = str(args.port)
            
            # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰èµ·å‹•ï¼ˆåˆ¥ãƒ—ãƒ­ã‚»ã‚¹ï¼‰
            frontend_cmd = [
                sys.executable, "-m", "streamlit", "run",
                "src/frontend/app.py",
                "--server.port", str(args.port + 1),
                "--server.address", "0.0.0.0",  # å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯
                "--server.headless", "true",
                "--browser.gatherUsageStats", "false"
            ]
            
            print(f"ğŸ–¥ï¸ ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚’èµ·å‹•: http://0.0.0.0:{args.port + 1}")
            print(f"   APIæ¥ç¶šå…ˆ: http://localhost:{args.port}")
            
            # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚’åˆ¥ãƒ—ãƒ­ã‚»ã‚¹ã§èµ·å‹•ï¼ˆç’°å¢ƒå¤‰æ•°ã‚’æ¸¡ã™ï¼‰
            frontend_process = subprocess.Popen(frontend_cmd, env=frontend_env)
            
            # APIã‚µãƒ¼ãƒãƒ¼ã‚’ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã§èµ·å‹•ï¼ˆãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
            try:
                subprocess.run(api_cmd)
            finally:
                # çµ‚äº†æ™‚ã«ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ—ãƒ­ã‚»ã‚¹ã‚‚çµ‚äº†
                frontend_process.terminate()
                frontend_process.wait()
        else:
            subprocess.run(api_cmd)
            
    except Exception as e:
        print(f"âŒ Webã‚¢ãƒ—ãƒªèµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


def full_process(args):
    """å…¨ä½“å‡¦ç†ï¼ˆå¼·åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰"""
    enhanced_mode = getattr(args, 'enhanced', False)
    skip_export = getattr(args, 'skip_export', False)
    
    if enhanced_mode:
        print("ğŸ”„ å…¨ä½“å‡¦ç†ã‚’é–‹å§‹ï¼ˆå¼·åŒ–ãƒ¢ãƒ¼ãƒ‰ï¼‰...")
        print("   âœ¨ å¼·åŒ–ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å«ã‚€å®Œå…¨å‡¦ç†")
    else:
        print("ğŸ”„ å…¨ä½“å‡¦ç†ã‚’é–‹å§‹...")
    
    if not skip_export:
        print("\n=== ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ===")
        export_data(args)
    else:
        print("\n=== ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰ ===")
    
    print("\n=== ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ™ã‚¯ãƒˆãƒ«åŒ– ===")
    if enhanced_mode:
        print("ğŸ¯ å¼·åŒ–ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
    vectorize_articles(args)
    
    print("\n=== ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ç¢ºèª ===")
    check_data(args)
    
    if enhanced_mode:
        print("\nğŸ‰ å…¨ä½“å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆå¼·åŒ–ãƒ¢ãƒ¼ãƒ‰ï¼‰ï¼")
        print("   âœ¨ é«˜ç²¾åº¦ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«ã‚ˆã‚‹æ¤œç´¢å“è³ªå‘ä¸Šã‚’å®Ÿç¾")
    else:
        print("\nğŸ‰ å…¨ä½“å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    # è¨­å®šç¢ºèª
    if args.command in ['export', 'full'] and not getattr(args, 'skip_export', False):
        if not settings.esa_api_token or not settings.esa_team_name:
            print("âŒ ESA_API_TOKEN ã¨ ESA_TEAM_NAME ã‚’ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„")
            sys.exit(1)
    
    print(f"=== ç ”ç©¶å®¤RAGã‚·ã‚¹ãƒ†ãƒ  - {args.command} ===")
    print(f"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
    command_functions = {
        'export': export_data,
        'vectorize': vectorize_articles,
        'check': check_data,
        'search': search_articles,
        'serve': serve_app,
        'full': full_process
    }
    
    if args.command in command_functions:
        command_functions[args.command](args)
    else:
        print(f"âŒ ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {args.command}")
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    main()
